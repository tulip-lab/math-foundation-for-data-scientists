[![GitHub watchers](https://img.shields.io/badge/tulip--lab-Math--Foundations-brightgreen)](../README.md)
[![GitHub watchers](https://img.shields.io/badge/Module-Matrix--Factorization(III)-orange)](README.md)

# Matrix Factorization (III)

`Singular Value Decomposition` (SVD) and `Non-negative Matrix Factorization` (NNMF) are two powerful techniques in linear algebra and data analysis, widely used for their unique capabilities in decomposing matrices.

SVD is a fundamental matrix factorization method that decomposes any given matrix into three other matrices: U (an orthogonal matrix), Î£ (a diagonal matrix with non-negative singular values), and V* (the conjugate transpose of an orthogonal matrix). This decomposition is highly versatile and forms the backbone of many applications in signal processing, statistics, and machine learning, particularly in dimensionality reduction techniques like Principal Component Analysis (PCA). SVD is renowned for its ability to identify the inherent structure in a matrix, capturing the essence of the data in a lower-dimensional space.

NNMF, on the other hand, specializes in decomposing a matrix into two non-negative matrices, often interpreted as the features and coefficients. This constraint of non-negativity makes NNMF particularly useful in applications like image processing, text mining, and collaborative filtering, where negative values are not meaningful. NNMF is adept at providing interpretable decompositions, making it a valuable tool for exploratory data analysis and pattern discovery in large datasets. Both SVD and NNMF are integral to the field of data science, offering robust methods for data exploration, compression, and interpretation.

## :notebook_with_decorative_cover: Lecture Slides Handouts

- [Lecture: Matrix Factorization (III)](https://github.com/tulip-lab/handouts/blob/main/LinearAlgebra/FLIP13.pdf) 

